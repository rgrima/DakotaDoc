%! program = pdflatex

%\documentclass[12pt,a4paper]{memoir} % for a long document
%\documentclass[12pt,a4paper,article]{memoir} % for a short document
\documentclass[12pt,a4paper,article]{memoir}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={210mm,297mm},
 left=20mm,
 right=20mm,
 top=20mm,
 bottom=20mm,
 }
% \usepackage[titletoc]{appendix}

\usepackage{graphicx}
\usepackage{listings}
\usepackage[dvipsnames]{xcolor}
\usepackage{hyperref}
\usepackage{cleveref}

%\lstset{frame=tb,
%  language=C++,
%  aboveskip=3mm,
%  belowskip=3mm,
%  showstringspaces=false,
%  columns=flexible,
%  basicstyle={\small\ttfamily},
%  numbers=none,
%  numberstyle=\tiny\color{mygray},
%  keywordstyle=\color{blue},
%  commentstyle=\color{mygreen},
%  stringstyle=\color{mymauve},
%  breaklines=true,
%  breakatwhitespace=true,
%  tabsize=2
%}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 

\lstdefinestyle{MyCodeStyle} {
%  language=C++, % choose the language of the code
  backgroundcolor=\color{backcolour},
  commentstyle=\color{codegreen},
  keywordstyle=\color{magenta},
  numberstyle=\tiny\color{codegray},
  stringstyle=\color{codepurple},
  basicstyle=\footnotesize,
  breakatwhitespace=false,
  breaklines=true,
  captionpos=b, % sets the caption-position to bottom
  keepspaces=true,                 
  numbers=none, % where to put the line-numbers
  showspaces=false, % show spaces adding particular underscores
  showstringspaces=false, % underline spaces within strings
  showtabs=false, % show tabs within strings adding particular underscores
  frame=single, % adds a frame around the code
  tabsize=2, % sets default tabsize to 2 spaces
  rulesepcolor=\color{blue},
  rulecolor=\color{black},
  xleftmargin=.1\textwidth,
  xrightmargin=.1\textwidth,
}

\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\graphicspath{ {./img/} }
% See the ``Memoir customise'' template for some common customisations
% Don't forget to read the Memoir manual: memman.pdf

\title{Optimizing Alya simulations of multi-physics problems with Dakota}
\author{Rogeli Grima}
%\date{10/12/2014} % Delete this line to display the current date

% Make appear "Appendix" in the ToC
\renewcommand*{\cftappendixname}{Appendix\space}

%%% BEGIN DOCUMENT
\begin{document}

\maketitle
\tableofcontents*

\chapter{Introduction}

Dakota is a toolkit that provides a flexible, extensible interface between analysis codes and iterative systems analysis methods. It contains algorithms for optimization, uncertainty quantification, parameter estimation and sensitivity/variance analysis.

Alya is a computational method that is used to simulate complex physical systems. On many occasions we want to use these simulations to find an acceptable or optimized solution for a particular system. Dakota will help us to use Alya as a design tool. It will help us to solve very important questions as: What is the best design? How safe is it? How much confidence do I have in my answer?

This user's guide is intended to provide some background information on how to use Dakota to solve optimization problems that involve a simulation with Alya. We assume the user has some familiarity with Alya execution and configuration.

In this guide we will show how to use Dakota in Marenostrum, how to prepare your simulations with Alya, how to process their outputs and we will provide some basic examples.

\section{Dakota workflow}

Before you start working with Dakota and Alya, is important to know the Dakota's workflow. This will give you a better perspective of what is happening.

Dakota receives input and configuration from a variety of text files prepared by the user, and connects to any simulation code by other text files. This simple interface is one of the most important features of Dakota, as it makes it easy to change the iterative method or strategy by just changing a few lines in the Dakota input file.

In Figure \ref{fig:Workflow}, we can see the Dakota workflow. The user should provide an input file to Dakota. This input file controls the algorithm that we want to run, the function to be evaluated, the variables of this function and the outputs that we expect.

\begin{figure}[htb!]
  \centering
    \includegraphics[width=0.4\textwidth]{DakotaWorkflow}
  \caption{Dakota Workflow}
  \label{fig:Workflow}
\end{figure}

Dakota generates a parameter file for every function evaluation. This file contains a specific value of every variable and specifies the kind of returning values that it needs (function evaluation, derivatives or/and second derivatives).

Dakota treats the simulation code as a black box. Most of the codes, like Alya, don't know what to do with the parameter file, so it is common to create a script to connect the simulation code with Dakota. In this script we merge the Dakota parameters file with the simulation code input files. Once we have some proper input files we can run the simulation code, extract the significant data from its output files and post-process that data in order to generate the appropriate objective function and the Dakota results file.

\chapter{Dakota tutorial}
\section{Set up Dakota}

We have installed in Marenostrum the last three versions of Dakota. Althought, most of the experiments that we have ran have been done using version 5.4 we encourage you to use the last version. From now on, all the information that we will provide you in this guide will refer to version 6.1. You can find the several installed versions of Dakota in:

\begin{itemize}
\item \textit{/gpfs/projects/bsc21/DAKOTA/dakota-5.4.0}
\item \textit{/gpfs/projects/bsc21/DAKOTA/dakota-6.0.0}
\item \textit{/gpfs/projects/bsc21/DAKOTA/dakota-6.1.0}
\end{itemize}

If you want to install your own version of Dakota in Marenostrum, please check Appendix \ref{chapter:CodeMod}.


In order to run Dakota you will need to set the path of the executables and the directory of the shared libraries. You can add these lines to your .barshrc file:

\begin{lstlisting}[style=MyCodeStyle,language=bash]
export DAK_INSTALL=/gpfs/projects/bsc21/DAKOTA/dakota-6.1.0
export PATH=${DAK_INSTALL}/bin/:${PATH}
export LD_LIBRARY_PATH=${DAK_INSTALL}/bin:${LD_LIBRARY_PATH}
export LD_LIBRARY_PATH=${DAK_INSTALL}/lib:${LD_LIBRARY_PATH}
\end{lstlisting}

Check that everything is working properly by running:

\begin{lstlisting}[style=MyCodeStyle,language=bash]
dakota -v
\end{lstlisting}

\section{Runing Dakota with a simple input file}
This section is intended for users who are new to Dakota, to demonstrate the basics of running a simple example.

\begin{enumerate}
\item Create a working directory.
\item From path \textit{/gpfs/projects/bsc21/DAKOTA/Examples/power}, copy files \textit{power\_multidim.in} and \textit{power.py} to the working directory.
\item From the working directory, run: \textit{dakota -i power\_multidim.in -o power\_multidim.out \textgreater{} power\_multidim.stdout}
\end{enumerate}

Dakota outputs a large amount of information to help users track progress. Four files should have been created:
\begin{enumerate}
\item The screen output has been redirected to the file power\_multidim.stdout. The contents are messages from Dakota and notes about the progress of the iterator (i.e. method/algorithm).
\item The output file \textit{power\_multidim.out} contains information about the function evaluations.
\item \textit{power\_multidim.dat} is created due to an specification of the input file. This summarizes the variables and responses for each function evaluation.
\item \textit{dakota.rst} is a restart file. If a Dakota analysis is interrupted, it can be often be restarted without losing all progress.
\end{enumerate}

This example used a parameter study method and the \textit{power.py} test problem. The Python script \textit{power.py} reads a Dakota parameters file, computes the function $F(x,y)=(X-0.5)^2+(Y+0.5)^2$ and writes the result in a Dakota results file.

As we said, this is a parametric study. Let's try to execute an optimization problem. Now, copy file \textit{power\_mas.in} to your working directory and run:

%dakota -i  power\_mas.in -o power\_mas.out \textgreater{} power\_mas.stdout
\begin{lstlisting}[style=MyCodeStyle,language=bash]
dakota -i  power_mas.in -o power_mas.out > power_mas.stdout
\end{lstlisting}

This executes a mesh adaptive direct search algorithm. If you look at the output file you will see that the method converges in 160 iterations and propose as a best objective function a value of $F(X,Y)=0.0$ evaluated for $X=0.5$ and $Y=-0.5$ . That is the minimum of the evaluated function.

You can see a graphic representation of the results executing the script \textit{visualize.sh} that you can find in the same directory. This scripts reads the results from the parametric study and from the mesh adaptive direct search algorithm.

\begin{figure}[htb!]
  \centering
    \includegraphics[width=0.5\textwidth]{power}
  \caption{Mesh adaptive direct search evaluation points}
  \label{fig:Power}
\end{figure}

\section{Dakota input file format}

There are six sections in every Dakota input file. These sections are identified with the following keywords: \textit{variables}, \textit{interface}, \textit{responses}, \textit{model}, \textit{method}, and \textit{environment}. At least one \textit{variables}, \textit{interface}, \textit{responses}, and \textit{method} must appear, and no more than one \textit{environment} should appear.

\begin{figure}[htb!]
  \centering
    \includegraphics[width=0.8\textwidth]{DakotaInputFile}
  \caption{Relationship between the six blocks}
  \label{fig:InputFile}
\end{figure}

Figure \ref{fig:InputFile} shows the relationships between the six keyword blocks. The environment specifies high level Dakota settings, and identifies the top level method. A method runs a model. A model block defines the connections between variables, the interface, and responses. It shows the most common relationships between blocks but others are possible. Most Dakota analyses just needs to define a single method which runs a single model.

For a more concrete example, a simple Dakota input file, \textit{power\_multidim.in}, for a two-dimensional parameter study on $F(x,y)=(X-0.5)^2+(Y+0.5)^2$ function is shown in Figure \ref{fig:PoMuCode}. This input file will be used to describe the basic format and syntax used in all Dakota input files.

\begin{figure}[htb!]
\begin{lstlisting}[style=MyCodeStyle,language=bash]
environment
  tabular_graphics_data
    tabular_graphics_file = 'power_multidim.dat'

method
  multidim_parameter_study
    partitions = 8 8

model
  single

variables
  continuous_design = 2
    lower_bounds     -2.0     -2.0
    upper_bounds      2.0      2.0
    descriptors       "X"     "Y"

interface
  fork
    analysis_driver = './power.py'
    parameters_file = 'params'
    results_file    = 'results'
    file_save

responses
  response_functions = 1
  no_gradients
  no_hessians
\end{lstlisting}
\caption{File power\_multidim.in}
\label{fig:PoMuCode}
\end{figure}

First, some syntax background:
\begin{itemize}
\item Blocks can follow any order.
\item Comments starts with symbol \textit{\#}.
\item Use of single or double quotes for string inputs.
\item Use of commas and/or white spaces for separation of specifications.
\item The optional use of symbol \textit{=} to indicate supplied data.
\end{itemize}

The first block that we can find in the file is \textit{environment}. This keyword is used to specify the general Dakota settings such as Dakota's graphical output and the tabular data output (via the \textit{tabular\_graphics\_data} keyword).

The \textit{method} block of the input file specifies which iterative method Dakota will employ, such as a parameter study, optimization method, data sampling technique, etc. The keyword \textit{multidim\_parameter\_study} calls for a multidimensional parameter study, while the keyword \textit{partitions} specifies the number of intervals per variable. In this case, there will be eight intervals (nine data points) evaluated between the lower and upper bounds of both variables (bounds provided subsequently in the variables section), for a total of 81 response function evaluations.

The \textit{model} block of the input file specifies the model that Dakota will use. It provides the logical unit for determining how a set of variables is mapped into a set of responses in support of an iterative method. The model allows one to specify a single interface, or to manage more sophisticated mappings involving surrogates or nested iteration. 
Most of the time we are going to use the \textit{single} model, that is the default value for \textit{model} and its definition can be omitted.

The \textit{variables} block of the input file specifies the characteristics of the parameters that will be used in the problem formulation. The variables can be continuous or discrete, and can be classified as design variables, uncertain variables, or state variables. In figure \ref{fig:PoMuCode} you can see as we have defined two continuous design variables, with their upper and lower bounds and a name: X and Y.

The \textit{interface} block of the input file specifies what approach will be used to map variables into responses as well as details on how Dakota will pass data to and from a simulation code. In this example, the keyword \textit{fork} is used to indicate the use of a user-supplied program. Then we find four keywords: 
\begin{itemize}
\item \textit{analysis\_driver:} indicates the name of the program to execute. In this case, it is going to use the python program \textit{power.py}. 
\item \textit{parameters\_file:} name of the dakota parameters file that the driver would receive from Dakota.
\item \textit{results\_file:} name of the results file that the driver should return to Dakota once it has finished.
\item \textit{file\_save:} It's telling Dakota to not delete parameters and results files once the driver has finished.
\end{itemize}

Dakota will execute the external program like this:

\begin{lstlisting}[style=MyCodeStyle,language=bash]
./power.py params.$i results.$i
\end{lstlisting}

Where \$i is the iteration number of the method.

The \textit{responses} block of the input file specifies the types of data that the interface will return to Dakota. For our example, the assignment \textit{num\_objective\_functions = 1} indicates that there is only one objective function. Since there are no constraints associated with Rosenbrock's function, the keywords for constraint specifications are omitted. The keywords \textit{no\_gradients} and \textit{no_hessians} indicate that no
derivatives will be provided to the method; none are needed for a parameter study.

\appendix

\chapter{Dakota Source code modification}
\label{chapter:CodeMod}

Original code from Dakota has an incompatibility with the queue system of Marenostrum. The queue system kills all the asynchronous task that Dakota uses to run concurrent jobs. We have modified Dakota code to avoid this problem.

In the Linux Bash terminal, an orphan process can be created by attaching an ampersand at the end of the command line. This is an abstract of the original file CommandShell.cpp where we can see how Dakota runs asynchronous jobs:

\begin{lstlisting}[style=MyCodeStyle,language=C++]
CommandShell& CommandShell::flush()
{
  if (asynchFlag)
    sysCommand += " &";
  std::system(sysCommand.c_str());
}
\end{lstlisting}

As we can see, Dakota makes a system call using the ampersand when the asynchronous flag is true. In this case, the new process is orphan and this can became a problem. If we want to avoid this, we can not use the ampersand.

\begin{lstlisting}[style=MyCodeStyle,language=C++]
CommandShell& CommandShell::flush()
{
  if (asynchFlag)
  {
    if ( fork() == 0 )
    {
      std::system(sysCommand.c_str());
      exit( 0 );
    }
  }
  else
    std::system(sysCommand.c_str());
}
\end{lstlisting}

In the new version, we call fork to create a new Dakota process for each new simulation. We can identify the original process because the returning value of fork is different from zero. This process exits the function without doing anything. Meanwhile, the new process (its returning value from fork is equal to zero) makes the system call to execute the task, but without detaching it. The task is never an orphan process. Once the task is finished the process is terminated.

\end{document}
